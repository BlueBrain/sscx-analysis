{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation of SSCx analysis with topological sampling pipeline\n",
    "[https://github.com/BlueBrain/topological_sampling](https://github.com/BlueBrain/topological_sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import scipy.sparse as sps\n",
    "from bluepy import Simulation, Cell, Synapse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "- Neuron info (hex0 target): __neuron_info.pickle__\n",
    "- Spikes (hex0 target; EXC only): __raw_spikes.npy__\n",
    "- Stimulus train: __stim_stream.npy__\n",
    "- Adjacency matrix (hex0 target; re-indexed): __connectivity.npz__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_path = '/gpfs/bbp.cscs.ch/data/scratch/proj83/bbp_workflow/b0a99807-f1c4-41e0-a261-5fb4e718412d/000'\n",
    "# sim_path = '/gpfs/bbp.cscs.ch/data/scratch/proj83/bbp_workflow/f553e919-2fac-460c-a58e-3facc388da90/000'\n",
    "save_path = os.path.join(sim_path, 'toposample_input')\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "blue_config = os.path.join(sim_path, 'BlueConfig')\n",
    "sim = Simulation(blue_config)\n",
    "c = sim.circuit\n",
    "hex0 = c.cells.ids('hex0')\n",
    "\n",
    "spike_file = os.path.abspath(os.path.join(sim_path, sim.config['Stimulus_spikeReplay']['SpikeFile']))\n",
    "spike_config_file = os.path.splitext(spike_file)[0] + '.json'\n",
    "assert os.path.exists(spike_config_file), 'ERROR: Spike config file not found!'\n",
    "with open(spike_config_file, 'r') as f:\n",
    "    spike_config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neuron info\n",
    "neuron_info = c.cells.get(hex0, properties=[Cell.X, Cell.Y, Cell.Z, Cell.LAYER, Cell.MTYPE, Cell.SYNAPSE_CLASS])\n",
    "neuron_info.to_pickle(os.path.join(save_path, 'neuron_info.pickle'))\n",
    "neuron_info.to_hdf(os.path.join(save_path, 'neuron_info.h5'), 'neuron_info', format='table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/bbp.cscs.ch/ssd/apps/hpc/jenkins/deploy/libraries/2021-01-06/linux-rhel7-x86_64/gcc-9.3.0/py-numpy-1.19.4-upzqna/lib/python3.8/site-packages/numpy/lib/arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "# Excitatory spikes\n",
    "hex0_exc = neuron_info[neuron_info['synapse_class'] == 'EXC'].index\n",
    "raw_spikes = sim.spikes.get(hex0_exc)\n",
    "raw_spikes = np.vstack((raw_spikes.index, raw_spikes.to_numpy())).T\n",
    "np.save(os.path.join(save_path, 'raw_spikes.npy'), raw_spikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stim train\n",
    "stim_stream = np.array(spike_config['props']['stim_train'])\n",
    "np.save(os.path.join(save_path, 'stim_stream.npy'), stim_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjacency matrix\n",
    "conns = np.array(list(c.connectome.iter_connections(pre=hex0, post=hex0)))\n",
    "reindex_table = sps.csr_matrix((np.arange(neuron_info.shape[0], dtype=int), (np.zeros(neuron_info.shape[0], dtype=int), neuron_info.index.to_numpy())))\n",
    "conns_reindex = np.array([reindex_table[0, conns[:, d]].toarray().flatten() for d in range(conns.shape[1])]).T\n",
    "\n",
    "adj_matrix = sps.csc_matrix((np.full(conns_reindex.shape[0], True), conns_reindex.T.tolist()))\n",
    "sps.save_npz(os.path.join(save_path, 'connectivity.npz'), adj_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Toposample input files written to \"/gpfs/bbp.cscs.ch/data/scratch/proj83/bbp_workflow/b0a99807-f1c4-41e0-a261-5fb4e718412d/000/toposample_input\": ['neuron_info.pickle', 'neuron_info.h5', 'connectivity.npz', 'stim_stream.npy', 'raw_spikes.npy']\n"
     ]
    }
   ],
   "source": [
    "print(f'INFO: Toposample input files written to \"{save_path}\": {os.listdir(save_path)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-convert dataframe from .h5 to .pickle\n",
    "- In case pickled dataframe has wrong protocol\n",
    "- Should be saved with same python/pandas version as used in toposample analysis (e.g., using same venv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File written to /gpfs/bbp.cscs.ch/data/scratch/proj83/bbp_workflow/b0a99807-f1c4-41e0-a261-5fb4e718412d/000/toposample_input/neuron_info.pickle!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# camp_id = '4073e95f-abb1-4b86-8c38-13cf9f00ce0b'\n",
    "# save_path = f'/gpfs/bbp.cscs.ch/data/scratch/proj83/home/pokorny/analyses/proj96/{camp_id}/toposample_input_merged'\n",
    "save_path = '/gpfs/bbp.cscs.ch/data/scratch/proj83/bbp_workflow/b0a99807-f1c4-41e0-a261-5fb4e718412d/000/toposample_input'\n",
    "h5_file = os.path.join(save_path, 'neuron_info.h5')\n",
    "pickle_file = os.path.splitext(h5_file)[0] + '.pickle'\n",
    "neuron_info = pd.read_hdf(h5_file)\n",
    "if os.path.exists(pickle_file):\n",
    "    os.rename(pickle_file, os.path.splitext(pickle_file)[0] + '_BAK_' + os.path.splitext(pickle_file)[1])\n",
    "neuron_info.to_pickle(pickle_file)\n",
    "print(f'File written to {pickle_file}!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BbpWorkflowKernel",
   "language": "python",
   "name": "bbpworkflowkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
